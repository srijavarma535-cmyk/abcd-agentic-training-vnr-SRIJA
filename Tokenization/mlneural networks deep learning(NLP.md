ML>neural networks >deep learning(NLP)>transformers(interface, architecture based on LLMS )>LLM(practical)

ai vs ml => agentic AI





deep learning (neural networks with multiple layers)

LARGE LANGUAGE MODEL(VERY LARGE TRANSFORMERS TRAINED ON TEXT) 

Generative AI(AI that generates text, images ,audio etc)

Agentic AI(LLMS as agents that can act autonomously)





                          

**overall: AGENT{LLM(limited tokens ,cloud),TOOLS(apis, methods, functions) ,resource, integrated with email**



**open AI{sk-proj-\_hb1lI98jB\_qNdaB4o4C7Tp2Jvm-\_5AHBpnayCgne3ojTqMGTuppQaJP49q2sXfjR9tUJVIXpaT3BlbkFJC\_ERzVd15iyh1osTsqRImwsMKfEDf7GEeV7kWH4IjX9iwaFd7\_\_7s6nULZwoJZysonIanmO8MA}**



**{Google AI studio:AIzaSyAmm6jUz5lD0UcBbySP9UitPpwi\_TV\_xbw}**



                                                                                                                                           

**LINEAR REGRESSION** 



correct line = accuracy more and error is less



payload ,authentication , header == api keys



git status

cd../

git add

git commit-" Add deep learning . ipnyb "

git push

&nbsp;             

Tokenization ---> Embedding -->(**Attention-->MLP-->Residual + Normalization)**--->Unembedding

&nbsp;                                               |

&nbsp;                                               |

&nbsp;                                      (whole purpose to reduce noise)  

&nbsp;      1                                                      2                                                       3                                    4          

|red||||
|-|-|-|-|
|<br />fox<br />||||
|is||||
|alive<br />in <br />forest||||







**package managers:**

npm

pip

npn

yarn

maven

opt

**\*\*\*uv(UV sink)**



ass:

cosine similarity

tokenization





**(open ai-->framework-->nocodenocode)**





